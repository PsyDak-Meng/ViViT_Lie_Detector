{"cells":[{"cell_type":"markdown","metadata":{"id":"O4h-UIaM22z6"},"source":["# CS 6476 Computer Vision: VIVIT Lie Detector Project"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7865,"status":"ok","timestamp":1713194863123,"user":{"displayName":"Che-Ting Meng","userId":"01832823181779290658"},"user_tz":240},"id":"oCkKGmmwtaci"},"outputs":[{"name":"stderr","output_type":"stream","text":["Access is denied.\n"]}],"source":["!pip -q install einops\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1414,"status":"ok","timestamp":1713194864531,"user":{"displayName":"Che-Ting Meng","userId":"01832823181779290658"},"user_tz":240},"id":"zuVd4j-1t8mL","outputId":"453be767-d0cb-45f4-ef15-725427fa69d7"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/My Drive/ViViT_Lie_Detector\u001b[39m\u001b[38;5;124m'\u001b[39m:\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","if os.getcwd() != '/content/drive/My Drive/ViViT_Lie_Detector':\n","  os.chdir('drive/MyDrive/ViViT_Lie_Detector')\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12634,"status":"ok","timestamp":1713194877158,"user":{"displayName":"Che-Ting Meng","userId":"01832823181779290658"},"user_tz":240},"id":"phmD8cypt1JR"},"outputs":[],"source":["import torch\n","from torch import nn, einsum\n","import torch.nn.functional as F\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","from module import Attention, PreNorm, FeedForward\n","import numpy as np\n","from math import ceil\n","import argparse\n","from CONSTANTS import BATCH_SIZE, PATCH_SIZE, IMG_SIZE, FRAME_NUM\n","import zipfile\n","from tqdm import tqdm\n","import io\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from vivit import ViViT, Transformer\n","from Trainer import VIVIT_Trainer\n","import matplotlib.pyplot as plt\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1713194877158,"user":{"displayName":"Che-Ting Meng","userId":"01832823181779290658"},"user_tz":240},"id":"ZPzmZlSOv7VB","outputId":"3d400887-1064-4e18-83ed-4a439fe07b90"},"outputs":[{"name":"stdout","output_type":"stream","text":["using cpu device...\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'using {device} device...')"]},{"cell_type":"markdown","metadata":{"id":"JeGRsz7j5yTv"},"source":["### Loading Processed Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231132,"status":"ok","timestamp":1713195108277,"user":{"displayName":"Che-Ting Meng","userId":"01832823181779290658"},"user_tz":240},"id":"5Ux9abUj52d8","outputId":"2b55790a-0f94-43ce-af8b-f6f62b7de030"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 957/957 [03:51<00:00,  4.14it/s]"]},{"name":"stdout","output_type":"stream","text":["318\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["w = 480\n","h = 640\n","c = 3\n","\n","img_dataset = []\n","''' _old/stack for midterm/final '''\n","# img_archive = zipfile.ZipFile('Processing_results/filtered_image_stack_old.zip', 'r')\n","img_archive = zipfile.ZipFile('Processing_results/filtered_image_stack.zip', 'r')\n","\n","for file in tqdm(img_archive.infolist()):\n","  if file.filename.endswith('.npy'):\n","    with img_archive.open(file) as npy_file:\n","      img = np.load(io.BytesIO(npy_file.read()))\n","      if img.shape[1] == w and img.shape[2] == h and img.shape[3] == c:\n","        img_dataset.append(img)\n","print(len(img_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1713195108278,"user":{"displayName":"Che-Ting Meng","userId":"01832823181779290658"},"user_tz":240},"id":"H30OJ2Tc76Nv","outputId":"02747aa7-5401-4168-df87-9bbdbab093d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["120\n"]}],"source":["# find max t\n","t_max = 0\n","\n","for img in img_dataset:\n","  t_max = max(t_max, img.shape[0])\n","  # ensure unified frames\n","  # assert img.shape[1] == w and img.shape[2] == h and img.shape[3] == c\n","  if not (img.shape[1] == w and img.shape[2] == h and img.shape[3] == c):\n","    print(\"inconsistent shape: \",img.shape)\n","print(t_max)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBApUZuXASKB","outputId":"39730953-67f4-4839-dced-ed26c5f6ce61"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 318/318 [00:06<00:00, 49.86it/s]\n"]}],"source":["# ImageDataset\n","img_tensors = []\n","for img in tqdm(img_dataset):\n","  img_tensors.append(torch.tensor(img))\n","train_dataloader = torch.nn.utils.rnn.pad_sequence(img_tensors, batch_first=True)\n","print(train_dataloader.shape) # (sample_size,frames,height,width,channel)\n","N,T,H,W,C = train_dataloader.shape\n","\n","# train_dataloader = train_dataloader.reshape(N,T,C,H,W) --incorrect shaping!!\n","train_dataloader = train_dataloader.permute(0,1,4,2,3) # correct shaping\n","print(train_dataloader.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAgEvEjAaqgA"},"outputs":[],"source":["def show_image(img):\n","  img = np.float32(img.detach().numpy().astype(int)/255.0)\n","  print(img.shape)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  plt.imshow(img)\n","\n","# show frame example\n","show_image(train_dataloader[0][0].permute(1,2,0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1jRBcTnDNSs"},"outputs":[],"source":["# Labels\n","label_archive = zipfile.ZipFile('MU3D_dataset.zip', 'r')\n","for file in tqdm(label_archive.infolist()):\n","  if file.filename.endswith('.xlsx'):\n","    with label_archive.open(file) as label_file:\n","      label = pd.read_excel(label_file, sheet_name='Video-Level Data')\n","      # display(label.head(3))\n","\n","y = torch.tensor(label['Veracity'].astype('float').values)\n","y = y[:61]\n","y = y.unsqueeze(1)\n","print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"qEWbyNMWCKXN"},"source":["### Train / Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WogxVzFoQ5g"},"outputs":[],"source":["print(N,T,H,W,C)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8F1xI_sJo4t8"},"outputs":[],"source":["# training and testing splt\n","X_train, X_test, y_train, y_test = train_test_split(train_dataloader, y, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zA9LsWLlYQHh"},"outputs":[],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ['TORCH_USE_CUDA_DSA'] = \"1\""]},{"cell_type":"markdown","metadata":{"id":"E9vi9xYsDP6y"},"source":["### Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tWCPp42xvxpY"},"outputs":[],"source":["# ViViT model\n","FRAME_NUM = T\n","model = ViViT(image_size_w=W, image_size_h=H,\n","                   patch_size_w=80, patch_size_h=60,\n","                     num_classes=1,\n","                     num_frames=FRAME_NUM, pool='cls').to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n","criterion = nn.BCELoss()\n","\n","Trainer = VIVIT_Trainer(model, optimizer, criterion)\n","# Trainer.train(X_train, X_test, y_train, y_test, BATCH_SIZE=4, num_epoch=1)"]},{"cell_type":"markdown","metadata":{"id":"nR8Urb3899YC"},"source":["### Classification Interpretabiity\n","- Attentionn weight extraction\n","- Emotions analysis on 6 emotions: <br>\n","{0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"} <br>\n","Using pretrained model from source: https://github.com/Dipeshtamboli/emotion-detection-using-TF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UcCPJcPv9_Ef"},"outputs":[],"source":["from Inference import VIVIT_Classifier\n","\n","X_sample = X_test[0].unsqueeze(0).float()\n","y_sample = y_test[0].float()\n","print('Input size: ',X_sample.shape)\n","\n","lie_detector = VIVIT_Classifier(model)\n","lie_detector.inference(X_sample, y_sample)\n","lie_detector.extract_attn_weights(n=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lmADNuZ9UAeq"},"outputs":[],"source":["%tb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6n2cE8xPt7T"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kb_198bBXHK5"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPtnhVe8Xcjo8/epDLJxNfq","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
